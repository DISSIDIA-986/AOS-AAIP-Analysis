"""
æ”¿ç­–ç¨³å®šæ€§ç›‘æ§æ¨¡å—
-------------------
ç›®çš„ï¼šæ£€æµ‹AAIPæŠ½ç­¾æ¨¡å¼çš„ç»“æ„æ€§å˜åŒ–ï¼Œè¯†åˆ«æ”¿ç­–è°ƒæ•´ä¿¡å·ã€‚
é€‚ç”¨åœºæ™¯ï¼š2025å¹´æ”¿ç­–ç›¸å¯¹ç¨³å®šï¼Œéœ€ç›‘æ§æœªæ¥æ”¿ç­–å˜åŒ–ä»¥å†³å®šæ˜¯å¦æ‰©å±•è®­ç»ƒæ•°æ®ã€‚
"""

from __future__ import annotations

from pathlib import Path
from typing import Dict, List

import numpy as np
import pandas as pd
from scipy.stats import ks_2samp, mannwhitneyu


def detect_concept_drift(
    df: pd.DataFrame,
    baseline_months: List[str] = ["2025-02", "2025-03", "2025-04"],
    test_months: List[str] = ["2025-10", "2025-11"],
    alpha: float = 0.05,
) -> Dict[str, Dict[str, float]]:
    """
    æ£€æµ‹æŠ½ç­¾æ¨¡å¼çš„åˆ†å¸ƒæ¼‚ç§»ï¼ˆConcept Driftï¼‰ã€‚

    æ–¹æ³•ï¼šKolmogorov-Smirnovæ£€éªŒæ¯”è¾ƒåŸºçº¿æœŸä¸æµ‹è¯•æœŸçš„é‚€è¯·æ•°åˆ†å¸ƒã€‚

    Args:
        df: æ¸…æ´—åçš„æŠ½ç­¾æ•°æ®
        baseline_months: åŸºçº¿æœŸæœˆä»½ï¼ˆæ”¿ç­–ç¨³å®šæ—©æœŸï¼‰
        test_months: æµ‹è¯•æœŸæœˆä»½ï¼ˆæœ€è¿‘æœˆä»½ï¼‰
        alpha: æ˜¾è‘—æ€§æ°´å¹³

    Returns:
        å„æµçš„KSæ£€éªŒç»“æœ {"stream": {"statistic": float, "p_value": float, "drift_detected": bool}}
    """
    results = {}

    for stream, g in df.dropna(subset=["invitations"]).groupby("stream"):
        if len(g) < 10:
            continue

        # åˆ†å‰²åŸºçº¿æœŸå’Œæµ‹è¯•æœŸ
        baseline = g[g["draw_date"].dt.to_period("M").astype(str).isin(baseline_months)]["invitations"]
        test = g[g["draw_date"].dt.to_period("M").astype(str).isin(test_months)]["invitations"]

        if len(baseline) < 3 or len(test) < 3:
            continue

        # KSæ£€éªŒï¼šæ£€æµ‹åˆ†å¸ƒæ˜¯å¦æ˜¾è‘—ä¸åŒ
        stat, p_value = ks_2samp(baseline, test)

        results[stream] = {
            "ks_statistic": round(float(stat), 4),
            "p_value": round(float(p_value), 4),
            "drift_detected": p_value < alpha,
            "baseline_mean": round(float(baseline.mean()), 2),
            "test_mean": round(float(test.mean()), 2),
            "mean_change_pct": round(float((test.mean() - baseline.mean()) / baseline.mean() * 100), 2),
        }

    return results


def detect_variance_change(
    df: pd.DataFrame,
    window_size: int = 10,
    threshold_multiplier: float = 2.0,
) -> Dict[str, List[str]]:
    """
    æ£€æµ‹é‚€è¯·æ•°æ–¹å·®çš„çªå˜ï¼ˆå¼‚å¸¸æ³¢åŠ¨ä¿¡å·ï¼‰ã€‚

    æ–¹æ³•ï¼šæ»šåŠ¨çª—å£æ ‡å‡†å·®ï¼Œæ£€æµ‹è¶…è¿‡é˜ˆå€¼çš„å¼‚å¸¸æ³¢åŠ¨æœŸã€‚

    Args:
        window_size: æ»šåŠ¨çª—å£å¤§å°ï¼ˆæŠ½ç­¾æ¬¡æ•°ï¼‰
        threshold_multiplier: å¼‚å¸¸é˜ˆå€¼å€æ•°ï¼ˆæ ‡å‡†å·®çš„å€æ•°ï¼‰

    Returns:
        å„æµçš„å¼‚å¸¸æ³¢åŠ¨æ—¥æœŸåˆ—è¡¨
    """
    anomalies = {}

    for stream, g in df.dropna(subset=["invitations"]).groupby("stream"):
        if len(g) < window_size + 5:
            continue

        g = g.sort_values("draw_date").copy()
        rolling_std = g["invitations"].rolling(window=window_size, min_periods=5).std()
        threshold = rolling_std.mean() + threshold_multiplier * rolling_std.std()

        anomaly_dates = g.loc[rolling_std > threshold, "draw_date"].dt.date.astype(str).tolist()

        if anomaly_dates:
            anomalies[stream] = anomaly_dates

    return anomalies


def generate_stability_report(df: pd.DataFrame, output_path: Path) -> None:
    """ç”Ÿæˆæ”¿ç­–ç¨³å®šæ€§ç›‘æ§æŠ¥å‘Šã€‚"""
    drift_results = detect_concept_drift(df)
    variance_anomalies = detect_variance_change(df)

    with open(output_path, "w", encoding="utf-8") as f:
        f.write("# AAIP æ”¿ç­–ç¨³å®šæ€§ç›‘æ§æŠ¥å‘Š\n\n")
        f.write("**ç›®çš„**: æ£€æµ‹2025å¹´AAIPæŠ½ç­¾æ¨¡å¼çš„ç»“æ„æ€§å˜åŒ–ï¼Œè¯†åˆ«æ”¿ç­–è°ƒæ•´ä¿¡å·ã€‚\n\n")

        f.write("## 1. åˆ†å¸ƒæ¼‚ç§»æ£€æµ‹ï¼ˆConcept Driftï¼‰\n\n")
        f.write("**æ–¹æ³•**: Kolmogorov-Smirnovæ£€éªŒæ¯”è¾ƒ2025å¹´æ—©æœŸï¼ˆ2-4æœˆï¼‰vs æ™šæœŸï¼ˆ10-11æœˆï¼‰é‚€è¯·æ•°åˆ†å¸ƒã€‚\n\n")

        if drift_results:
            f.write("| Stream | KSç»Ÿè®¡é‡ | p-value | æ¼‚ç§»æ£€æµ‹ | åŸºçº¿å‡å€¼ | æµ‹è¯•å‡å€¼ | å˜åŒ–% |\n")
            f.write("| --- | --- | --- | --- | --- | --- | --- |\n")
            for stream, res in drift_results.items():
                drift_flag = "âš ï¸ æ˜¯" if res["drift_detected"] else "âœ… å¦"
                f.write(
                    f"| {stream} | {res['ks_statistic']} | {res['p_value']} | "
                    f"{drift_flag} | {res['baseline_mean']} | {res['test_mean']} | {res['mean_change_pct']}% |\n"
                )
            f.write("\n**è§£è¯»**:\n")
            f.write("- p-value < 0.05 â†’ æ£€æµ‹åˆ°æ˜¾è‘—åˆ†å¸ƒæ¼‚ç§»ï¼Œå¯èƒ½å­˜åœ¨æ”¿ç­–è°ƒæ•´\n")
            f.write("- p-value â‰¥ 0.05 â†’ åˆ†å¸ƒç¨³å®šï¼Œ2025å¹´æ”¿ç­–åŒè´¨æ€§è‰¯å¥½\n\n")
        else:
            f.write("æ— è¶³å¤Ÿæ•°æ®è¿›è¡Œæ¼‚ç§»æ£€æµ‹ã€‚\n\n")

        f.write("## 2. æ–¹å·®çªå˜æ£€æµ‹\n\n")
        f.write("**æ–¹æ³•**: æ»šåŠ¨çª—å£æ ‡å‡†å·®ï¼Œæ£€æµ‹è¶…è¿‡æ­£å¸¸æ³¢åŠ¨2å€çš„å¼‚å¸¸æ³¢åŠ¨æœŸã€‚\n\n")

        if variance_anomalies:
            for stream, dates in variance_anomalies.items():
                f.write(f"### {stream}\n")
                f.write(f"å¼‚å¸¸æ³¢åŠ¨æ—¥æœŸ: {', '.join(dates)}\n\n")
        else:
            f.write("âœ… æœªæ£€æµ‹åˆ°å¼‚å¸¸æ³¢åŠ¨ï¼Œå„æµé‚€è¯·æ•°æ–¹å·®ç¨³å®šã€‚\n\n")

        f.write("## 3. æ•°æ®æ‰©å±•å»ºè®®\n\n")

        drift_count = sum(1 for res in drift_results.values() if res["drift_detected"])

        if drift_count == 0:
            f.write("âœ… **å»ºè®®**: 2025å¹´æ”¿ç­–ç¨³å®šï¼Œå¯å®‰å…¨ä½¿ç”¨2025å…¨å¹´æ•°æ®è®­ç»ƒæ¨¡å‹ã€‚\n\n")
            f.write("**æ‰©å±•ç­–ç•¥**: ä»…åœ¨2026å¹´å‰2ä¸ªæœˆæ•°æ®é€šè¿‡åŒè´¨æ€§æ£€éªŒåï¼Œå†è€ƒè™‘æ‰©å±•è®­ç»ƒé›†ã€‚\n\n")
        elif drift_count <= len(drift_results) / 2:
            f.write("âš ï¸ **å»ºè®®**: éƒ¨åˆ†æµæ£€æµ‹åˆ°æ¼‚ç§»ï¼Œå»ºè®®åˆ†æµå»ºæ¨¡æˆ–æ·»åŠ æ—¶é—´è¶‹åŠ¿ç‰¹å¾ã€‚\n\n")
        else:
            f.write("ğŸš¨ **è­¦å‘Š**: å¤šæ•°æµæ£€æµ‹åˆ°æ˜¾è‘—æ¼‚ç§»ï¼Œå¯èƒ½å­˜åœ¨æ”¿ç­–è°ƒæ•´ã€‚\n\n")
            f.write("**å»ºè®®**: ä½¿ç”¨æœ€è¿‘3-6ä¸ªæœˆæ•°æ®é‡æ–°è®­ç»ƒï¼Œé¿å…ä½¿ç”¨æ•´ä¸ª2025å¹´æ•°æ®ã€‚\n\n")

        f.write("---\n\n")
        f.write("**ç”Ÿæˆæ—¶é—´**: " + pd.Timestamp.now().strftime("%Y-%m-%d %H:%M") + "\n")


def run() -> None:
    """æ‰§è¡Œæ”¿ç­–ç¨³å®šæ€§ç›‘æ§ã€‚"""
    df = pd.read_csv("data/processed/aaip_draws_2025.csv", parse_dates=["draw_date"])
    output_path = Path("reports/policy_stability_report.md")
    output_path.parent.mkdir(parents=True, exist_ok=True)

    generate_stability_report(df, output_path)
    print(f"æ”¿ç­–ç¨³å®šæ€§æŠ¥å‘Šå·²ç”Ÿæˆ -> {output_path}")


if __name__ == "__main__":
    run()
